{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0083273",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a1529",
   "metadata": {},
   "source": [
    "**Author:** Seda Radoykova, Science Executive (21/22), UCL DSS\n",
    "\n",
    "**Date:** 11 Jan, 2022\n",
    "\n",
    "***Proudly presented by the UCL Data Science Society***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306700b",
   "metadata": {},
   "source": [
    "## Classification problems in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9f7c9",
   "metadata": {},
   "source": [
    "Supervised machine learning algorithms build models based on labeled data sets. The models use the labelled data in the learning process. Also known as fitting, this is the process of adjusting the weights of the different data points. Problems in machine learning can therefore be broadly divided into **classification** and **regression**. We have already seen examples of applying regression to continuous prediction problems: linear regression. But as we know, data can broadly be defined into categorical and continuous. Can we use regression for categorical data? \n",
    "<br> <br>\n",
    "The answer is yes, and this is the basis of **logistic regression**, the topic of this workshop. \n",
    "<br><br>\n",
    "Confusingly, the predictions from logistic regression are used to *categorise/classify* data, *i.e.* predict which category an observation belongs to, based on its features. Some questions we might ask are for example, \"How likely is a person to suffer from a disease (**outcome**) given their age, sex, smoking status, *etc* (**varibles/features**)?\" \"How likely is this email to be spam?\" \"Will a student pass a test given some predictors of performance?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327bef0",
   "metadata": {},
   "source": [
    "It is important to keep in mind the distinction between **independent** and **dependent** variables:\n",
    "<br>\n",
    "* **Independent variable** (inputs or predictors) - as the name suggests, these should be independent of the outcome of interest (assume so!).\n",
    "* **Dependent variables** (outputs or responses) - these depend on the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae24dde",
   "metadata": {},
   "source": [
    "Further to this, classification problems can be divided into:\n",
    "<br>\n",
    "* **Binary** or **binomial classification** - two possible outcomes (0 or 1, true or false, positive or negative, pass or fail, healthy or sick, spam or not spam).\n",
    "* **Multiclass** or **multinomial classification** - three or more possible outputs (healthy, diease 1, disease 2). \n",
    "* **Ordinal** logistic regression - similar to multinomial, except the dependent variables have ordinal significance (for example, UK degree classification or restaurant ratings). \n",
    "<br><br>\n",
    "We will only consider binary classification for the sake of simplicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91e5ff",
   "metadata": {},
   "source": [
    "### Software prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics # contains classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc9084",
   "metadata": {},
   "source": [
    "## Define problem, set scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef45125",
   "metadata": {},
   "source": [
    "### Some background maths: the sigmoid function and a little bit of probability theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65239c5b",
   "metadata": {},
   "source": [
    "- The **sigmoid function** is also known as an S-shaped curve. \n",
    "- It is defined as: <br>\n",
    "$\\sigma(x) = \\frac{1}{1+e^{-x}}$ <br>\n",
    "- Note (see graph below) how most values are very close to either 0 or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a sigmoid function by hand\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "\n",
    "# evaluate the sigmoid at some x values\n",
    "sigm = np.arange(-22, 22, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sigmoid\n",
    "plt.plot(sigm*0.2+4.57, np.array(sigmoid(sigm)), color = \"red\") # manually implemented sigmoid\n",
    "plt.plot([0,10], [0.5, 0.5], linestyle = \"dotted\", color = \"black\") \n",
    "plt.title(\"Sigmoid function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7993ca9",
   "metadata": {},
   "source": [
    "- You might see the term **logit** function (logistic unit). \n",
    "- The logit function is the inverse of the sigmoid function, $\\sigma^{-1}$. \n",
    "- Therefore: <br>\n",
    "$logit(p) = \\sigma^{-1}(p) = \\ln(\\frac{p}{1-p})$ for $p \\in (0;1)$ <br>\n",
    "- This is effectively the (natural) logarithm of the **odds ratio**. \n",
    "- Hence, logit is also known as the log-odds. \n",
    "- **Odds** is the probability that something happens divided by the probability it does not happen: <br>\n",
    "$\\frac{p}{1-p}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40bef0",
   "metadata": {},
   "source": [
    "_This entire detour is to focus on our attention on how it is that we decide whether the predicted outcome will be 0 or 1 - it is all a matter of **probability**. (The **probability** of passing or failing, winning or losing, being healthy or diseased.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535a5c7",
   "metadata": {},
   "source": [
    "Let's actually start framing the problem by saying that we have a set of independent variables $ X = (x_1 , ... x_r )$, where $r$ is the number of predictors/inputs. We would like to predict the bonary outcome $y$. We have some known values of $x_i$ for which we have observed the corresponding $y_i$ and our data set consists of $n$ such pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74ac9c",
   "metadata": {},
   "source": [
    "Therefore, our goal is to fit the **logistic regression function** to our data, minimisiing the distance between the predicted (line) and the observed (dots) outcomes. Once we know the **parameters** of the logistic function, we can use it to predict unobserved values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322d888",
   "metadata": {},
   "source": [
    "Coming back to the sigmoid function:\n",
    "<br> $\\sigma(x) = \\frac{1}{1+e^{-x}}$ <br>\n",
    "In the place of $-x$, let's put the **linear predictor** function $f(x) = \\beta_0 + \\beta_1x_1 + ... + \\beta_rx_r $. (The same linear predictor which we used for linear regression!) <br>\n",
    "The sigmoid becomes the logistic regression function $p(x)$:\n",
    "<br> $p(x) = \\frac{1}{1+e^{-f(x)}}$ \n",
    "<br> $p(x) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1x_1 + ... + \\beta_rx_r)}}$ <br>\n",
    "$\\beta_0, \\beta_1, ..., \\beta_r$ are known as the **estimators**, **coefficients**, or **predicted weights**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5f1a3",
   "metadata": {},
   "source": [
    "Therefore, $p(x)$ can be treated as *the probability that the output for a given input is equal to* **1**, *i.e.* $P(y = 1)$ . Conversely, the probability that the output of a given input is equal to **0** is given by $1-p(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3e9e3",
   "metadata": {},
   "source": [
    "Therefore, **model fitting** or **training** in logistic regression is the process of determining the optimal values of the coefficients $\\beta_0, \\beta_1, ..., \\beta_r$, such that the distance between the curve and the data points for each $y_i$ is as close as possible. There are many model fitting approaches, the most commonly used one being maximum-likelihood estimation (MLE). While it is beyond the scope of this tutorial, in the simplest terms we *optimise the likelihood function of the parameters given the data*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88826a7a",
   "metadata": {},
   "source": [
    "Notably, simply determining the weights is **not enough** to conclude our classification problem because we only have the *probability* that a given input is equal to 1 (or 0). We need a cutoff, a shortcut! <br> For example, for binary regression it makes sense for the algorithm to classify an input as 1 if $p>0.5$. Depending on the application, a different cutoff may be chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccf000",
   "metadata": {},
   "source": [
    "### Briefly comparing linear regression to logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1a085",
   "metadata": {},
   "source": [
    "Before we look at our data and the way we actually implement logicstic regression in Pyhton, let's dwell on the similarities and differences between linear and logistic regresion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate some very arbitrary data\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba84d53",
   "metadata": {},
   "source": [
    "Below, I will evaluate the linear and logistic regression function for this arbitrary dataset. (We will go through the details in a moment, just run these chunks...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03847c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a linear and a logistic regression model\n",
    "## we'll see how that's done in more detail further on, this is just an illustration ## \n",
    "linr = LinearRegression().fit(x, y)\n",
    "logr = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076875de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"red\") # scatterplot of data\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.5, 9.5])\n",
    "plt.plot(x, linr.predict(x), color = \"green\") # linear regression\n",
    "plt.plot(x, logr.predict(x), color = \"blue\") # logistic regression model\n",
    "#plt.plot(sigm*0.2+4.57, np.array(sigmoid(sigm)), color = \"black\") # manually implemented sigmoid\n",
    "plt.plot([0,10], [0.5, 0.5], linestyle = \"dotted\", color = \"black\") # our cutoff\n",
    "plt.title(\"Linear vs Logistic regression\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353efd25",
   "metadata": {},
   "source": [
    "Since the logistic regression (blue) looks a bit too exact, let's plot our smoother sigmoid curve from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"red\") # scatterplot of data\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.5, 9.5])\n",
    "plt.plot(x, linr.predict(x), color = \"green\") # linear regression\n",
    "#plt.plot(x, logr.predict(x), color = \"blue\") # logistic regression model\n",
    "plt.plot(sigm*0.2+4.57, np.array(sigmoid(sigm)), color = \"black\") # manually implemented sigmoid\n",
    "plt.plot([0,10], [0.5, 0.5], linestyle = \"dotted\", color = \"black\") # our cutoff\n",
    "plt.title(\"Linear vs Logistic regression / Sigmoid\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039215d",
   "metadata": {},
   "source": [
    "Note how the linear regression used here would still give *some* meaningful results. But the sigmoid is able to cover the entire dataset much more thoroughly and elegantly. <br>\n",
    "Moreover, the dotted line at $y=0.5$ is that cutoff which I have been going on about all this time. Given our data (red), we find the sigmoid line, *i.e.* logistic regression function (black) with parameters such, that the black line is as close to the data as possible. <br> Then, when we evaluate a new observation, that is simply a dot somewhere on the black line. If the \"dot\" is in the upper part of the plane (above our cut-off), it is classified as a 1, otherwise, it is a 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412e822",
   "metadata": {},
   "source": [
    "## Introducing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830927f",
   "metadata": {},
   "source": [
    "We will use a dataset from [Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database) to *predict whether a person has diabetes based on several variables*. The data are a subset from a larger database from the National Institute of Diabetes and Digestive and Kidney Diseases. All the subjects are females, 21+ years old, and of Pima Indian heritage. \n",
    "> The datasets consists of several medical predictor variables and one target variable. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115df8a",
   "metadata": {},
   "source": [
    "We have 8 predictors and one outcome. <br> \n",
    "- pregnancies = number of previous pregancies\n",
    "- glucose = blood glucose levels from a glucose tolerance test\n",
    "- bp = diastolic blood pressure values (mm Hg) \n",
    "- skin_thickness = triceps skin fold thickness (mm)\n",
    "- insulin = levels of insulin \n",
    "- bmi = body mass index (BMI), $\\frac{weight}{ height^2} = \\frac{kg}{m^2}$\n",
    "- pedigree = diabetes pedigree function\n",
    "- age = age (years)\n",
    "- outcome = health outcome (1 = diabetic, 0 = healthy)\n",
    "\n",
    "You don't necessarily need to understand what relationship (if any??) these have with diabetes. The beauty of being a data scientist is that someone thought about the relationship between the variables at the stage of data collection - your task is to look at the models and evaluate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7d945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "diabetes = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# check for missing values\n",
    "print(\"NaNs in data frame.\\n\") if diabetes.isnull().values.any() else print(\"No missing values.\\n\")\n",
    "\n",
    "# print head\n",
    "print(diabetes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb438ef",
   "metadata": {},
   "source": [
    "Let's split our data into features and targets. Further, let's split the entire data set into training and testing subsets. We will use 75% of the data to train the model and 25% to test its performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e918aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features/inputs and targets/outputs\n",
    "feature_cols = ['pregnancies', 'insulin', 'bmi', 'age', 'glucose', 'bp', 'pedigree']\n",
    "X = diabetes[feature_cols] # features\n",
    "y = diabetes.outcome # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eda81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cbd13",
   "metadata": {},
   "source": [
    "## Model training/fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and train it\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b45af5",
   "metadata": {},
   "source": [
    "We have just created an instance of a `LogisticRegression` object. <br>\n",
    "`model.LogisticRegression` will have several parameters of which some immediately interesting mich be: \n",
    "\n",
    "- `fit_intercept` - Boolean, decides whether to calculate the intercept $\\beta_0$ (when True, deafult) or consider it equal to zero (when False). \n",
    "- `intercept_scaling` - floating-point number, defines the scaling of the intercept $\\beta_0$, (1.0 by default). \n",
    "- `class_weight` - dictionary, 'balanced', or `None` (default), defines the weights related to each class. When `None`, all classes have the weight one.\n",
    "- `solver` - string, what solver to use for fitting the model. 'liblinear' by default; other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "- `tol` - floating-point number, defines the tolerance for stopping the procedure (0.0001 by default).\n",
    "- `n_jobs` - integer or `None` (default), defines the number of parallel processes to use. `None` usually means to use one core, while -1 means to use all available cores.\n",
    "\n",
    "There are many other parameters which you are encouraged to explore in more complex applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d0c7f",
   "metadata": {},
   "source": [
    "Having created a model, we now need to train it. This is done simply by supplying the training feature set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cfd53",
   "metadata": {},
   "source": [
    "`.fit()` requires the independent (`x`), and dependent (`y`) variables. It can also take observation-related weights. It fits the model and returns the model instance itself: <br>\n",
    "`LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,     \n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,             \n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',                \n",
    "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,    \n",
    "                   warm_start=False)                                           `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an elecgant one line model creation and fitting can be done as follows: \n",
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28197c2",
   "metadata": {},
   "source": [
    "Taking advantage of attributes, we can retrieve the intercept, $\\beta_0$, and the slopes, $\\beta_1, ..., \\beta_r$, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9816e8",
   "metadata": {},
   "source": [
    "Note that the intercept is in a one-dimensional array, whereas the coefficients (slopes) are in a two-dimensional array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e1172",
   "metadata": {},
   "source": [
    "## Evaluating Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06a6bd",
   "metadata": {},
   "source": [
    "Once we have fit our model, we would be interested in evaluating how well the classifier is performing. While in a good mdel, many of the predictions will be accurate, still,, inevitably, there will be errors. Sometimes the model will misplace healthy individuals with diabetic ones (false-positives) or *vice versa*, diabetic individuals will be classified as healthy (false-negatives). Therefore, there is a wealth of measures we can use to understand and evaluate the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7887db",
   "metadata": {},
   "source": [
    "- **Accuracy** = the ratio between the number of correct predictions and the total number of predictions. $ = \\frac{TP + TN}{TP + TN + FP + FN} $. It is the simplest and most intuitive measure of performance.  \n",
    "- **Precision** $ = \\frac{TP}{TP + FP} $.\n",
    "- **Sensitivity (recall,  true positive rate)** $ = \\frac{TP}{(TP + FN)} $.\n",
    "- **Specificity** $ = \\frac{TN}{(TN + FP)} $.\n",
    "- **Confusion matrix** - a 2x2 matrix with diagonal entries representing accurate predictions, and non-diagonal entries being inaccurate predictions. \n",
    "    - True negatives (TN): correctly predicted negatives (0)\n",
    "    - True positives(TP): correctly predicted positives (1)\n",
    "    - False negatives (FN): incorrectly predicted negatives (0)\n",
    "    - False positives (FP): incorrectly predicted positives (1)\n",
    "- **F1 score** $ = 2* \\frac{precision*recall}{precision+recall}$\n",
    "\n",
    "The positive predictive value is the ratio of the number of true positives to the sum of the numbers of true and false positives.\n",
    "The negative predictive value is the ratio of the number of true negatives to the sum of the numbers of true and false negatives.\n",
    "\n",
    "The specificity (or true negative rate) is the ratio of the number of true negatives to the number of actual negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153073c",
   "metadata": {},
   "source": [
    "But how do we actually get these metrics in Python? \n",
    "<br><br>\n",
    "Let's first make some predictions. `.predict_proba()` returns a matrix of probailities that the predicted output is equal to 0 or 1. <br>\n",
    "The first column is the probability of the predicted output being 0, that is 1 - ùëù(ùë•). <br>\n",
    "The second column is the probability that the output is 1, or ùëù(ùë•)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_train)[0:5] # let's just look at the output of a few"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51e85a",
   "metadata": {},
   "source": [
    "Remember that the logistic regression only returns *a probability* that an individual is diseased or not, not a definitive answe. The answer comes from our \"cut-off\": $P=0.5$ in this case. Hence, to obtain actual predictions, we would use `.predict()`, which returns the predicted outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d10703",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "print(\"Accuracy for test set is {}.\".format(round(metrics.accuracy_score(y_test, y_pred), 4)*100))\n",
    "print(\"Precision for test set is {}.\".format(round(metrics.precision_score(y_test, y_pred), 4)*100))\n",
    "print(\"Recall for test set is {}.\".format(round(metrics.recall_score(y_test, y_pred), 4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8825174",
   "metadata": {},
   "source": [
    "We can also get a classification report which includes precision, recall, and the f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600be652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25180fa6",
   "metadata": {},
   "source": [
    "We could obtain a confusion matrix using one line of code too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the confusion matrix\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d18cb",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2acdc",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC)** curve is anoher characteristic plot which you will see everywhere in machine learning contexts. It plots the true positive rate against the false positive rate, showing the tradeoff between *sensitivity* and *specificity*. The **area under the curve (AUC)** showws how close the classifier is to ideal performance. Therefore, the \"best\" ROC curve of a model with 100% specificity and sensitivity would look like an upside-down L, and the AOC would be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22117d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=\"data 1, auc = \" + str(round(auc*100,2)))\n",
    "plt.plot([0,0], [0,1], color = \"violet\") # ideal curve\n",
    "plt.plot([0,1], [1,1], color = \"violet\") # ideal curve \n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257aa32d",
   "metadata": {},
   "source": [
    "In the visualisation above, the ROC curve is shown in blue, while the \"ideal\" ROC curve is in violet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf976cd",
   "metadata": {},
   "source": [
    "# NOT SURE IF I SHOULD TALK ABOUT OVERFITTING, COLLINEARITY, AND MODEL SELECTION??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4e856",
   "metadata": {},
   "source": [
    "Later on, we will discuss some of the limitations of logistic regression. In particular, this classifier often suffers from overfitting and collinearty. Both of these have consequences for model selection and the conscious decision which variables to include in the model. <br>\n",
    "(This is the bit where understanding the relationships between the different variables and the source of the data can be important.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80df313",
   "metadata": {},
   "source": [
    "## Overfitting \n",
    "**Overfitting** is a common problem for complex models in machine learning. It is when the model learns the training data too well and is unable to make accurate preductions with new inputs (test data). This happens because the model learns the noise the data! <br><br>\n",
    "**Regularisation** can come to the rescue in this case. Regularisation penalises complexity in models. In the case of logistic regression, regularisation would penalise large coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8412d",
   "metadata": {},
   "source": [
    "To give some examples of regularisation: \n",
    "- **L1** = penalise the log-likelihood function using the scaled sum of the **absolute values** of the parameters. \n",
    "- **L2** = penalise the log-likelihood function using the scaled sum of the **squares** of the parameter values. \n",
    "- **Elastic-net** = a linear combination of **L1** and **L2**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b87388",
   "metadata": {},
   "source": [
    "## Collinearity\n",
    "Collinearity is a common problem which occurs when your input/independent variables are not truly independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d9fe6",
   "metadata": {},
   "source": [
    "## Model selction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64637ff4",
   "metadata": {},
   "source": [
    "## Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1cc78",
   "metadata": {},
   "source": [
    "We have leared how to implement a simple case of the logistic regression. As we saw, logistic regression is a relatively intuitive, efficient, and elegant classification technique which provides us with a probability for a given outcome given some observation. This makes it a very popular classifier. There are several advantages to using logistic regression. Many would say that the main one is that it does not require high computational power. In addition, it is easy to implement, even from scratch, and the interpretation is straightforward. \n",
    "<br><br>\n",
    "Despite the great popularity enjoyed by logistic regression, it's important to keep in mind that it suffers several shortcomings. One of the main limitations to keep in mind is that it cannot handle highly complex models with many predictor variables. In addition, to give meaningful predictions, logistic regression models need to be trained on large samples. Logistic regression models are prone to overfitting. They cannot solve non-linear problems; hence, they require non-linear data to be transformed. If the dependency between the independent and the dependent variable is weak, the classifier will not perform well. In addition, if the independent variables are not in fact independent, the model performance will suffer from collinearity. \n",
    "<br><br>\n",
    "Still, there is a wealth of other classification techniques which could be used as alternatives. We will cover these in future workshops. \n",
    "- Naive Bayes classifiers\n",
    "- Support vector machines (SVM)\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b1bae",
   "metadata": {},
   "source": [
    "# Further resources and links consulted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e2a64",
   "metadata": {},
   "source": [
    "- Here's an example of a multiple regression model: [classifying images of digits](https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a). \n",
    "- A very detailed [RealPython tutorial](https://realpython.com/logistic-regression-python/), most of this workshop is based on the information provided.\n",
    "- A wonderful [DataCamp tutorial](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python) providing the basis of the data analysis. \n",
    "\n",
    "And further reading wth more examples for those interested.\n",
    "- https://asperbrothers.com/blog/logistic-regression-in-python/  \n",
    "- https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8  \n",
    "- https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "- https://www.nature.com/articles/nmeth.3904\n",
    "- https://www.ibm.com/cloud/learn/supervised-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
